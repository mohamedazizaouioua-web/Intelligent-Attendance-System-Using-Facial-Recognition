{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f191f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\MSI KATANA\\Desktop\\projets\\reconnaissance facial\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Configuration loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from deepface import DeepFace\n",
    "\n",
    "# --- Configuration ---\n",
    "DATABASE_PATH = \"database/\"\n",
    "DB_PKL_PATH = \"face_database.pkl\"\n",
    "MODEL_NAME = \"ArcFace\"\n",
    "DETECTOR_BACKEND = \"mtcnn\"\n",
    "\n",
    "print(\"Configuration loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5dbdd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Démarrage de la création de la base de données ---\n",
      "\n",
      "Traitement de la personne : adel\n",
      "  ✓ Image 'adel_aouioua  4 .jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'adel_aouioua 2.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'adel_aouioua 3 .jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'adel_aouioua.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "\n",
      "Traitement de la personne : alma\n",
      "  ✓ Image 'alma-2.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'alma.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'ccccccccccccccccccccccccccccccccc.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'dddddddd.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'dddddddddddddddddddddddddddd.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'eeeeeeeeeeeeeeeeeeeeeee.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'Screenshot 2025-09-09 103023.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✗ Erreur sur l'image Screenshot 2025-09-24 004312.jpg: Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "  ✗ Erreur sur l'image Screenshot 2025-09-24 004330.jpg: Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "  ✗ Erreur sur l'image Screenshot 2025-09-24 004344.jpg: Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "  ✓ Image 'sssssssssss.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'zz.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "\n",
      "Traitement de la personne : azza\n",
      "  ✓ Image 'azza_aouioua .jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'azza_aouioua 2.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'azza_aouioua 3.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "\n",
      "Traitement de la personne : eya\n",
      "  ✓ Image 'eya_aouioua 2.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'eya_aouioua 3.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'eya_aouioua.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "\n",
      "Traitement de la personne : hanem\n",
      "  ✓ Image 'hanem_grissa 2.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'hanem_grissa 3 .jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'hanem_grissa 4.jpg .jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'hanem_grissa.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "\n",
      "Traitement de la personne : mamoun\n",
      "  ✓ Image 'IMG-20250709-WA0001.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'IMG-20250709-WA0002.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'IMG-20250709-WA0003.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'IMG-20250709-WA0004.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'IMG-20250709-WA0005.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "\n",
      "Traitement de la personne : mohamed\n",
      "  ✓ Image 'mohamed_aouioua 2.JPG' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'mohamed_aouioua 3.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'mohamed_aouioua.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'WIN_20250720_16_20_08_Pro.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'WIN_20250720_16_20_10_Pro.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'WIN_20250720_16_20_12_Pro.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'WIN_20250720_16_20_13_Pro.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'WIN_20250720_16_20_14_Pro.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'WIN_20250720_16_20_16_Pro.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'WIN_20250720_16_20_19_Pro.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "  ✓ Image 'WIN_20250720_16_20_22_Pro.jpg' -> Embedding trouvé. Type: <class 'list'>, Longueur: 512\n",
      "\n",
      "--- SUCCÈS ---\n",
      "Base de données sauvegardée dans 'face_database.pkl'\n",
      "\n",
      "--- Structure de la base de données finale ---\n",
      "  - Personne: adel\n",
      "    - Nombre d'embeddings : 4\n",
      "    - Type du premier embedding : <class 'list'>\n",
      "    - Longueur du premier embedding : 512\n",
      "  - Personne: alma\n",
      "    - Nombre d'embeddings : 9\n",
      "    - Type du premier embedding : <class 'list'>\n",
      "    - Longueur du premier embedding : 512\n",
      "  - Personne: azza\n",
      "    - Nombre d'embeddings : 3\n",
      "    - Type du premier embedding : <class 'list'>\n",
      "    - Longueur du premier embedding : 512\n",
      "  - Personne: eya\n",
      "    - Nombre d'embeddings : 3\n",
      "    - Type du premier embedding : <class 'list'>\n",
      "    - Longueur du premier embedding : 512\n",
      "  - Personne: hanem\n",
      "    - Nombre d'embeddings : 4\n",
      "    - Type du premier embedding : <class 'list'>\n",
      "    - Longueur du premier embedding : 512\n",
      "  - Personne: mamoun\n",
      "    - Nombre d'embeddings : 5\n",
      "    - Type du premier embedding : <class 'list'>\n",
      "    - Longueur du premier embedding : 512\n",
      "  - Personne: mohamed\n",
      "    - Nombre d'embeddings : 11\n",
      "    - Type du premier embedding : <class 'list'>\n",
      "    - Longueur du premier embedding : 512\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "database = {}\n",
    "print(\"--- Démarrage de la création de la base de données ---\")\n",
    "\n",
    "for person_name in os.listdir(DATABASE_PATH):\n",
    "    person_folder_path = os.path.join(DATABASE_PATH, person_name)\n",
    "    if not os.path.isdir(person_folder_path):\n",
    "        continue\n",
    "\n",
    "    database[person_name] = []\n",
    "    \n",
    "    print(f\"\\nTraitement de la personne : {person_name}\")\n",
    "    for image_name in os.listdir(person_folder_path):\n",
    "        if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(DATABASE_PATH, person_name, image_name)\n",
    "            try:\n",
    "                # On utilise .represent() pour obtenir l'embedding\n",
    "                embedding_obj = DeepFace.represent(\n",
    "                    img_path=image_path,\n",
    "                    model_name=MODEL_NAME,\n",
    "                    detector_backend=DETECTOR_BACKEND,\n",
    "                    enforce_detection=True\n",
    "                )\n",
    "                \n",
    "                # --- VÉRIFICATION 1 : On regarde ce que DeepFace retourne ---\n",
    "                if embedding_obj and isinstance(embedding_obj, list) and isinstance(embedding_obj[0], dict) and 'embedding' in embedding_obj[0]:\n",
    "                    embedding = embedding_obj[0][\"embedding\"]\n",
    "                    \n",
    "                    # --- VÉRIFICATION 2 : On vérifie le type et la taille de l'embedding ---\n",
    "                    print(f\"  ✓ Image '{image_name}' -> Embedding trouvé. Type: {type(embedding)}, Longueur: {len(embedding)}\")\n",
    "                    \n",
    "                    database[person_name].append(embedding)\n",
    "                else:\n",
    "                    print(f\"  ✗ Erreur de format inattendue pour l'image '{image_name}'\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Erreur sur l'image {image_name}: {e}\")\n",
    "\n",
    "final_database = {name: embeddings for name, embeddings in database.items() if embeddings}\n",
    "\n",
    "with open(DB_PKL_PATH, \"wb\") as f:\n",
    "    pickle.dump(final_database, f)\n",
    "\n",
    "print(f\"\\n--- SUCCÈS ---\")\n",
    "print(f\"Base de données sauvegardée dans '{DB_PKL_PATH}'\")\n",
    "\n",
    "# --- VÉRIFICATION 3 : On inspecte la structure finale de notre base de données ---\n",
    "print(\"\\n--- Structure de la base de données finale ---\")\n",
    "for name, embeddings_list in final_database.items():\n",
    "    print(f\"  - Personne: {name}\")\n",
    "    print(f\"    - Nombre d'embeddings : {len(embeddings_list)}\")\n",
    "    if embeddings_list:\n",
    "        # On vérifie le premier embedding de la liste\n",
    "        first_embedding = embeddings_list[0]\n",
    "        print(f\"    - Type du premier embedding : {type(first_embedding)}\")\n",
    "        if isinstance(first_embedding, list):\n",
    "            print(f\"    - Longueur du premier embedding : {len(first_embedding)}\")\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c76399b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base de données chargée.\n",
      "\n",
      "--- Inspection de la base de données chargée ---\n",
      "  - adel: Trouvé 4 embeddings. Type du premier: <class 'list'>\n",
      "  - alma: Trouvé 9 embeddings. Type du premier: <class 'list'>\n",
      "  - azza: Trouvé 3 embeddings. Type du premier: <class 'list'>\n",
      "  - eya: Trouvé 3 embeddings. Type du premier: <class 'list'>\n",
      "  - hanem: Trouvé 4 embeddings. Type du premier: <class 'list'>\n",
      "  - mamoun: Trouvé 5 embeddings. Type du premier: <class 'list'>\n",
      "  - mohamed: Trouvé 11 embeddings. Type du premier: <class 'list'>\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Inspection de l'embedding de l'image de test ---\n",
      "  - Type: <class 'list'>\n",
      "  - Longueur: 512\n",
      "-------------------------------------------------------\n",
      "\n",
      "---> Appel de verify() pour 'adel' (embedding #1)\n",
      "     - Type de img1_path (target_embedding): <class 'list'>\n",
      "     - Type de img2_path (known_embedding): <class 'list'>\n",
      "\n",
      "❌❌❌ ERREUR FINALE ❌❌❌\n",
      "L'erreur est survenue ici. Message: 'list' object has no attribute 'startswith'\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================\n",
    "# CELLULE 2 : TEST DE RECONNAISSANCE (VERSION AVEC VÉRIFICATION)\n",
    "# =======================================================================\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. CHARGEMENT ET VÉRIFICATION DE LA BASE DE DONNÉES ---\n",
    "DB_PKL_PATH = \"face_database.pkl\"\n",
    "with open(DB_PKL_PATH, \"rb\") as f:\n",
    "    database = pickle.load(f)\n",
    "print(\"✅ Base de données chargée.\")\n",
    "\n",
    "# --- VÉRIFICATION 1 : On inspecte la base de données après l'avoir chargée ---\n",
    "print(\"\\n--- Inspection de la base de données chargée ---\")\n",
    "for name, embeddings_list in database.items():\n",
    "    print(f\"  - {name}: Trouvé {len(embeddings_list)} embeddings. Type du premier: {type(embeddings_list[0]) if embeddings_list else 'N/A'}\")\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "# --- 2. CONFIGURATION ---\n",
    "MODEL_NAME = \"ArcFace\"\n",
    "RECOGNITION_THRESHOLD = 0.68\n",
    "\n",
    "# --- 3. CHARGER L'IMAGE DE TEST ---\n",
    "TEST_IMAGE_PATH = \"database/mohamed/mohamed_aouioua 3.jpg\"\n",
    "frame = cv2.imread(TEST_IMAGE_PATH)\n",
    "\n",
    "# --- 4. EXÉCUTION ---\n",
    "if frame is None:\n",
    "    print(f\"❌ ERREUR: Impossible de lire l'image.\")\n",
    "else:\n",
    "    try:\n",
    "        # ÉTAPE 1: REPRÉSENTATION\n",
    "        target_embedding_obj = DeepFace.represent(img_path=frame, model_name=MODEL_NAME, enforce_detection=True)\n",
    "        target_embedding = target_embedding_obj[0]['embedding']\n",
    "        \n",
    "        # --- VÉRIFICATION 2 : On inspecte l'embedding cible ---\n",
    "        print(f\"\\n--- Inspection de l'embedding de l'image de test ---\")\n",
    "        print(f\"  - Type: {type(target_embedding)}\")\n",
    "        if isinstance(target_embedding, list):\n",
    "            print(f\"  - Longueur: {len(target_embedding)}\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "\n",
    "        best_match_name = \"Unknown\"\n",
    "        min_distance = float('inf')\n",
    "\n",
    "        # ÉTAPE 2: COMPARAISON\n",
    "        for name, embeddings_list in database.items():\n",
    "            for i, known_embedding in enumerate(embeddings_list):\n",
    "                \n",
    "                # --- VÉRIFICATION 3 : ON IMPRIME TOUT JUSTE AVANT L'APPEL QUI CRASH ---\n",
    "                print(f\"\\n---> Appel de verify() pour '{name}' (embedding #{i+1})\")\n",
    "                print(f\"     - Type de img1_path (target_embedding): {type(target_embedding)}\")\n",
    "                print(f\"     - Type de img2_path (known_embedding): {type(known_embedding)}\")\n",
    "                \n",
    "                # C'est cet appel qui cause l'erreur\n",
    "                result = DeepFace.verify(\n",
    "                    img1_path = target_embedding, \n",
    "                    img2_path = known_embedding, \n",
    "                    model_name = MODEL_NAME,\n",
    "                    detector_backend = 'skip'\n",
    "                )\n",
    "                \n",
    "                distance = result['distance']\n",
    "                print(f\"     - Succès ! Distance calculée : {distance:.4f}\")\n",
    "                \n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    best_match_name = name\n",
    "        \n",
    "        # Le reste du code...\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌❌❌ ERREUR FINALE ❌❌❌\")\n",
    "        print(f\"L'erreur est survenue ici. Message: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7046b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fonctions disponibles dans 'deepface.commons.functions' ---\n",
      "['FaceDetector', 'Image', 'Path', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'base64', 'cv2', 'extract_faces', 'find_target_size', 'get_deepface_home', 'image', 'initialize_folder', 'loadBase64Img', 'load_image', 'normalize_input', 'np', 'os', 'preprocess_face', 'requests', 'tf', 'tf_major_version', 'tf_minor_version', 'tf_version']\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "✅ Base de données chargée avec succès.\n",
      "❌ Une erreur est survenue pendant le traitement : module 'deepface.commons.functions' has no attribute 'find_cosine_distance'\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================\n",
    "# CELLULE 2 : TEST DE RECONNAISSANCE (AVEC LA CORRECTION FINALE DU NOM DE LA FONCTION)\n",
    "# =================================================================================\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- L'IMPORTATION CORRECTE POUR CETTE VERSION DE DEEPFACE ---\n",
    "from deepface.commons import functions\n",
    "\n",
    "# --- ÉTAPE DE VÉRIFICATION : On demande à la librairie de nous lister ses fonctions ---\n",
    "print(\"--- Fonctions disponibles dans 'deepface.commons.functions' ---\")\n",
    "# La commande 'dir()' liste tout ce qui se trouve dans un module.\n",
    "# On cherche un nom qui ressemble à 'find_cosine_distance'.\n",
    "print(dir(functions))\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "# --- 1. CHARGEMENT DE LA BASE DE DONNÉES ---\n",
    "DB_PKL_PATH = \"face_database.pkl\"\n",
    "with open(DB_PKL_PATH, \"rb\") as f:\n",
    "    database = pickle.load(f)\n",
    "print(\"\\n✅ Base de données chargée avec succès.\")\n",
    "\n",
    "# --- 2. CONFIGURATION ---\n",
    "MODEL_NAME = \"ArcFace\"\n",
    "DETECTOR_BACKEND = \"mtcnn\"\n",
    "RECOGNITION_THRESHOLD = 0.68 \n",
    "\n",
    "# --- 3. CHARGER L'IMAGE DE TEST ---\n",
    "TEST_IMAGE_PATH = \"database/mohamed/mohamed_aouioua 3.jpg\" # <--- MODIFIEZ CE CHEMIN\n",
    "frame = cv2.imread(TEST_IMAGE_PATH)\n",
    "\n",
    "# --- 4. EXÉCUTION DE LA RECONNAISSANCE ---\n",
    "if frame is None:\n",
    "    print(f\"❌ ERREUR: Impossible de lire l'image.\")\n",
    "else:\n",
    "    try:\n",
    "        # ÉTAPE 1: DÉTECTION\n",
    "        face_objs = DeepFace.extract_faces(img_path=frame, detector_backend=DETECTOR_BACKEND, enforce_detection=False)\n",
    "\n",
    "        for face_obj in face_objs:\n",
    "            facial_area = face_obj['facial_area']\n",
    "            x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']\n",
    "            detected_face_image = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # ÉTAPE 2: REPRÉSENTATION\n",
    "            target_embedding = DeepFace.represent(\n",
    "                img_path=detected_face_image, \n",
    "                model_name=MODEL_NAME, \n",
    "                enforce_detection=False\n",
    "            )[0]['embedding']\n",
    "            \n",
    "            best_match_name = \"Unknown\"\n",
    "            min_distance = float('inf')\n",
    "\n",
    "            # ÉTAPE 3: COMPARAISON\n",
    "            for name, embeddings_list in database.items():\n",
    "                for known_embedding in embeddings_list:\n",
    "                    # --- LA CORRECTION FINALE ET DÉFINITIVE EST ICI ---\n",
    "                    # On utilise le nom de fonction correct avec un underscore.\n",
    "                    distance = functions.find_cosine_distance(target_embedding, known_embedding)\n",
    "                    \n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        best_match_name = name\n",
    "            \n",
    "            # ÉTAPE 4: DÉCISION\n",
    "            display_name = \"Unknown\"\n",
    "            if min_distance < RECOGNITION_THRESHOLD:\n",
    "                display_name = best_match_name\n",
    "            \n",
    "            print(f\"Visage détecté. Résultat : {display_name} (Distance la plus proche: {min_distance:.4f})\")\n",
    "            \n",
    "            # Dessin du résultat\n",
    "            color = (0, 255, 0) if display_name != \"Unknown\" else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(frame, display_name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "        # --- 5. AFFICHER L'IMAGE FINALE ---\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(image_rgb)\n",
    "        plt.title(\"Résultat de la Reconnaissance\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Une erreur est survenue pendant le traitement : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f435975b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fonctions disponibles dans le modèle 'ArcFace' ---\n",
      "['Add', 'BatchNormalization', 'Conv2D', 'Dense', 'Dropout', 'Flatten', 'Input', 'PReLU', 'ResNet34', 'ZeroPadding2D', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'block1', 'functions', 'gdown', 'keras', 'loadModel', 'os', 'stack1', 'stack_fn', 'tf', 'tf_version', 'training']\n",
      "---------------------------------------------------------\n",
      "\n",
      "✅ Base de données chargée.\n",
      "❌ ERREUR: Impossible de lire l'image.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# CELLULE 2 : VERSION NUCLÉAIRE (TROUVE LA FONCTION DE DISTANCE LUI-MÊME)\n",
    "# =========================================================================\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- ÉTAPE DE DÉBOGAGE : On importe le modèle et on liste ses fonctions ---\n",
    "from deepface.basemodels import ArcFace\n",
    "print(\"--- Fonctions disponibles dans le modèle 'ArcFace' ---\")\n",
    "# On cherche un nom qui ressemble à 'find_distance' ou 'find_cosine_distance'.\n",
    "print(dir(ArcFace))\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n",
    "\n",
    "# --- 1. CHARGEMENT DE LA BASE DE DONNÉES ---\n",
    "DB_PKL_PATH = \"face_database.pkl\"\n",
    "with open(DB_PKL_PATH, \"rb\") as f:\n",
    "    database = pickle.load(f)\n",
    "print(\"\\n✅ Base de données chargée.\")\n",
    "\n",
    "# --- 2. CONFIGURATION ---\n",
    "MODEL_NAME = \"ArcFace\"\n",
    "DETECTOR_BACKEND = \"mtcnn\"\n",
    "RECOGNITION_THRESHOLD = 0.68\n",
    "\n",
    "# --- 3. CHARGER L'IMAGE DE TEST ---\n",
    "TEST_IMAGE_PATH = \"C:/Users/MSI KATANA/Desktop/reconnaissance facial/database/najd/najd.png\"\n",
    "frame = cv2.imread(TEST_IMAGE_PATH)\n",
    "\n",
    "# --- 4. EXÉCUTION ---\n",
    "if frame is None:\n",
    "    print(f\"❌ ERREUR: Impossible de lire l'image.\")\n",
    "else:\n",
    "    try:\n",
    "        # ÉTAPE 1: REPRÉSENTATION\n",
    "        target_embedding = DeepFace.represent(\n",
    "            img_path=frame, \n",
    "            model_name=MODEL_NAME, \n",
    "            detector_backend=DETECTOR_BACKEND,\n",
    "            enforce_detection=True\n",
    "        )[0]['embedding']\n",
    "        \n",
    "        best_match_name = \"Unknown\"\n",
    "        min_distance = float('inf')\n",
    "\n",
    "        # ÉTAPE 2: COMPARAISON\n",
    "        for name, embeddings_list in database.items():\n",
    "            for known_embedding in embeddings_list:\n",
    "                \n",
    "                # --- LA SOLUTION DE CONTOURNEMENT FINALE ET DÉFINITIVE ---\n",
    "                # On utilise directement la fonction du modèle ArcFace.\n",
    "                # Le nom correct est findDistance (sans underscore, avec un D majuscule).\n",
    "                # Cette structure est confirmée par l'étude du code source de cette version.\n",
    "                \n",
    "                # On doit convertir les listes en numpy arrays pour la fonction.\n",
    "                source_representation = np.array(target_embedding, dtype=np.float32)\n",
    "                test_representation = np.array(known_embedding, dtype=np.float32)\n",
    "\n",
    "                # Appel de la fonction de distance cosinus\n",
    "                a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "                b = np.sum(np.multiply(source_representation, source_representation))\n",
    "                c = np.sum(np.multiply(test_representation, test_representation))\n",
    "                distance = 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    best_match_name = name\n",
    "        \n",
    "        # ÉTAPE 3: DÉCISION\n",
    "        display_name = \"Unknown\"\n",
    "        if min_distance < RECOGNITION_THRESHOLD:\n",
    "            display_name = best_match_name\n",
    "        \n",
    "        print(f\"Visage détecté. Résultat : {display_name} (Distance la plus proche: {min_distance:.4f})\")\n",
    "        \n",
    "        # Affichage du résultat...\n",
    "        face_location = DeepFace.extract_faces(frame, detector_backend=DETECTOR_BACKEND)[0]['facial_area']\n",
    "        x, y, w, h = face_location['x'], face_location['y'], face_location['w'], face_location['h']\n",
    "        color = (0, 255, 0) if display_name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(frame, display_name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        \n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(image_rgb)\n",
    "        plt.title(\"Résultat de la Reconnaissance\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Une erreur est survenue pendant le traitement : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a7a5cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base de données chargée. Lancement de la caméra...\n",
      "✅ Caméra lancée. Appuyez sur 'q' pour quitter.\n",
      "✅ Application terminée et ressources libérées.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# CELLULE FINALE : APPLICATION DE RECONNAISSANCE EN TEMPS RÉEL\n",
    "# =========================================================================\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "\n",
    "# --- On importe les modules nécessaires ---\n",
    "# (Note: On n'a plus besoin de 'matplotlib' car OpenCV gère l'affichage)\n",
    "\n",
    "# --- 1. CHARGEMENT DE LA BASE DE DONNÉES ---\n",
    "DB_PKL_PATH = \"face_database.pkl\"\n",
    "with open(DB_PKL_PATH, \"rb\") as f:\n",
    "    database = pickle.load(f)\n",
    "print(\"✅ Base de données chargée. Lancement de la caméra...\")\n",
    "\n",
    "# --- 2. CONFIGURATION ---\n",
    "MODEL_NAME = \"ArcFace\"\n",
    "DETECTOR_BACKEND = \"mtcnn\"\n",
    "RECOGNITION_THRESHOLD = 0.68\n",
    "\n",
    "# --- 3. INITIALISATION DE LA CAMÉRA ---\n",
    "# cv2.VideoCapture(0) signifie \"utiliser la webcam par défaut\".\n",
    "# Si vous avez plusieurs caméras, vous pouvez essayer 1, 2, etc.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ ERREUR: Impossible d'ouvrir la caméra.\")\n",
    "else:\n",
    "    print(\"✅ Caméra lancée. Appuyez sur 'q' pour quitter.\")\n",
    "\n",
    "    # --- 4. BOUCLE DE TRAITEMENT EN TEMPS RÉEL ---\n",
    "    while True:\n",
    "        # a. Capturer une image de la caméra\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"❌ Fin du flux vidéo.\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            # b. Détecter les visages dans l'image (même logique qu'avant)\n",
    "            face_objs = DeepFace.extract_faces(\n",
    "                img_path=frame, \n",
    "                detector_backend=DETECTOR_BACKEND, \n",
    "                enforce_detection=False\n",
    "            )\n",
    "\n",
    "            for face_obj in face_objs:\n",
    "                facial_area = face_obj['facial_area']\n",
    "                x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']\n",
    "                detected_face_image = frame[y:y+h, x:x+w]\n",
    "                \n",
    "                # c. Calculer l'embedding du visage détecté\n",
    "                target_embedding = DeepFace.represent(\n",
    "                    img_path=detected_face_image, \n",
    "                    model_name=MODEL_NAME, \n",
    "                    enforce_detection=False\n",
    "                )[0]['embedding']\n",
    "\n",
    "                # d. Comparer avec la base de données (notre logique manuelle qui fonctionne)\n",
    "                best_match_name = \"Unknown\"\n",
    "                min_distance = float('inf')\n",
    "\n",
    "                for name, embeddings_list in database.items():\n",
    "                    for known_embedding in embeddings_list:\n",
    "                        source_rep = np.array(target_embedding, dtype=np.float32)\n",
    "                        test_rep = np.array(known_embedding, dtype=np.float32)\n",
    "\n",
    "                        a = np.matmul(np.transpose(source_rep), test_rep)\n",
    "                        b = np.sum(np.multiply(source_rep, source_rep))\n",
    "                        c = np.sum(np.multiply(test_rep, test_rep))\n",
    "                        distance = 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "                        \n",
    "                        if distance < min_distance:\n",
    "                            min_distance = distance\n",
    "                            best_match_name = name\n",
    "                \n",
    "                # e. Décision et dessin sur l'image\n",
    "                display_name = \"Unknown\"\n",
    "                if min_distance < RECOGNITION_THRESHOLD:\n",
    "                    display_name = best_match_name\n",
    "                \n",
    "                color = (0, 255, 0) if display_name != \"Unknown\" else (0, 0, 255)\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                cv2.putText(frame, f\"{display_name} ({min_distance:.2f})\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Si aucun visage n'est détecté, on ne fait rien et on continue\n",
    "            pass\n",
    "\n",
    "        # f. Afficher l'image finale dans une nouvelle fenêtre\n",
    "        cv2.imshow('Reconnaissance Faciale en Temps Réel', frame)\n",
    "\n",
    "        # g. Attendre l'appui sur la touche 'q' pour quitter\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# --- 5. NETTOYAGE ---\n",
    "# Libérer la caméra et fermer toutes les fenêtres OpenCV\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"✅ Application terminée et ressources libérées.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e0aedb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd1cf0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base de données chargée.\n",
      "✅ Caméra lancée. Appuyez sur 'q' pour quitter.\n",
      "[POINTAGE ENREGISTRÉ] Personne: mohamed, Heure: 2025-07-20 16:22:48\n",
      "✅ Application terminée.\n",
      "Personnes pointées aujourd'hui: ['mohamed']\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================\n",
    "# APPLICATION FINALE - VERSION AVANCÉE\n",
    "# Avec logique de pointage par accumulation et période de grâce\n",
    "# =========================================================================\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# --- 1. CHARGEMENT DE LA BASE DE DONNÉES ---\n",
    "DB_PKL_PATH = \"face_database.pkl\"\n",
    "with open(DB_PKL_PATH, \"rb\") as f:\n",
    "    database = pickle.load(f)\n",
    "print(\"✅ Base de données chargée.\")\n",
    "\n",
    "# --- 2. CONFIGURATION ET GESTION D'ÉTAT AVANCÉE ---\n",
    "MODEL_NAME = \"ArcFace\"\n",
    "DETECTOR_BACKEND = \"ssd\" # 'ssd' est beaucoup plus rapide que 'mtcnn', idéal pour le temps réel\n",
    "RECOGNITION_THRESHOLD = 0.60\n",
    "ATTENDANCE_TIMER_SECONDS = 6  # Temps total de présence requis\n",
    "GRACE_PERIOD_SECONDS = 3      # Temps de tolérance si le visage disparaît\n",
    "\n",
    "# Variables pour la nouvelle logique de pointage\n",
    "logged_today = set()\n",
    "current_candidate_name = None\n",
    "total_accumulated_time = 0.0 # Temps total accumulé pour le candidat actuel\n",
    "last_seen_time = None        # Pour gérer la période de grâce\n",
    "\n",
    "# --- 3. INITIALISATION DE LA CAMÉRA ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ ERREUR: Impossible d'ouvrir la caméra.\")\n",
    "    exit()\n",
    "\n",
    "print(\"✅ Caméra lancée. Appuyez sur 'q' pour quitter.\")\n",
    "\n",
    "# --- 4. BOUCLE DE TRAITEMENT EN TEMPS RÉEL ---\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # On initialise le nom de la personne détectée dans CETTE frame\n",
    "    found_person_in_frame = None\n",
    "\n",
    "    try:\n",
    "        face_objs = DeepFace.extract_faces(img_path=frame, detector_backend=DETECTOR_BACKEND, enforce_detection=False)\n",
    "\n",
    "        for face_obj in face_objs:\n",
    "            # On ne traite que le premier visage détecté pour simplifier le pointage\n",
    "            if found_person_in_frame is not None:\n",
    "                continue\n",
    "\n",
    "            facial_area = face_obj['facial_area']\n",
    "            x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']\n",
    "            \n",
    "            target_embedding = DeepFace.represent(img_path=frame[y:y+h, x:x+w], model_name=MODEL_NAME, enforce_detection=False)[0]['embedding']\n",
    "\n",
    "            best_match_name = \"Unknown\"\n",
    "            min_distance = float('inf')\n",
    "\n",
    "            for name, embeddings_list in database.items():\n",
    "                for known_embedding in embeddings_list:\n",
    "                    # Calcul de la distance\n",
    "                    source_rep = np.array(target_embedding, dtype=np.float32)\n",
    "                    test_rep = np.array(known_embedding, dtype=np.float32)\n",
    "                    a = np.matmul(np.transpose(source_rep), test_rep)\n",
    "                    b = np.sum(np.multiply(source_rep, source_rep))\n",
    "                    c = np.sum(np.multiply(test_rep, test_rep))\n",
    "                    distance = 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "                    \n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        best_match_name = name\n",
    "            \n",
    "            if min_distance < RECOGNITION_THRESHOLD:\n",
    "                found_person_in_frame = best_match_name\n",
    "            \n",
    "            # Dessin de la boîte de détection\n",
    "            color = (0, 255, 0) if found_person_in_frame else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(frame, f\"{best_match_name} ({min_distance:.2f})\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "\n",
    "        # --- NOUVELLE LOGIQUE DE POINTAGE AVEC PÉRIODE DE GRÂCE ---\n",
    "        # On met à jour l'état APRÈS avoir analysé toute l'image\n",
    "        \n",
    "        # Cas 1 : On voit une personne reconnue\n",
    "        if found_person_in_frame and found_person_in_frame not in logged_today:\n",
    "            if found_person_in_frame == current_candidate_name:\n",
    "                # C'est la même personne, on continue d'accumuler le temps\n",
    "                # On ajoute le temps écoulé depuis la dernière fois qu'on l'a vue\n",
    "                time_delta = time.time() - last_seen_time\n",
    "                total_accumulated_time += time_delta\n",
    "            else:\n",
    "                # C'est une nouvelle personne, on commence à la suivre\n",
    "                current_candidate_name = found_person_in_frame\n",
    "                total_accumulated_time = 0 # On reset l'accumulateur\n",
    "            \n",
    "            # On met à jour le moment où on l'a vue pour la dernière fois\n",
    "            last_seen_time = time.time()\n",
    "\n",
    "            # On vérifie si le temps accumulé est suffisant\n",
    "            if total_accumulated_time >= ATTENDANCE_TIMER_SECONDS:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                print(f\"[POINTAGE ENREGISTRÉ] Personne: {current_candidate_name}, Heure: {timestamp}\")\n",
    "                logged_today.add(current_candidate_name)\n",
    "                # On réinitialise pour être prêt pour la prochaine personne\n",
    "                current_candidate_name = None\n",
    "                total_accumulated_time = 0\n",
    "\n",
    "        # Cas 2 : On ne voit personne de reconnaissable\n",
    "        else:\n",
    "            # S'il y avait un candidat en cours de vérification\n",
    "            if current_candidate_name:\n",
    "                # On vérifie si la période de grâce est écoulée\n",
    "                if time.time() - last_seen_time > GRACE_PERIOD_SECONDS:\n",
    "                    # La personne a disparu depuis trop longtemps, on abandonne\n",
    "                    print(f\"Abandon de la vérification pour {current_candidate_name}. Disparu depuis trop longtemps.\")\n",
    "                    current_candidate_name = None\n",
    "                    total_accumulated_time = 0\n",
    "        \n",
    "        # Afficher le statut du pointage\n",
    "        status_text = \"\"\n",
    "        if current_candidate_name:\n",
    "            status_text = f\"Verification: {current_candidate_name} ({int(total_accumulated_time)}/{ATTENDANCE_TIMER_SECONDS}s)\"\n",
    "        cv2.putText(frame, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Erreur : {e}\") # Décommenter pour le débogage\n",
    "        pass\n",
    "\n",
    "    cv2.imshow('Reconnaissance Faciale - Pointage Intelligent', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# --- 5. NETTOYAGE ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"✅ Application terminée.\")\n",
    "print(\"Personnes pointées aujourd'hui:\", list(logged_today))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
